<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Qiang Zhang, å¼ å¼º, Remote Sensing, Image Processing, Deep Learning, Denoising, Cloud Removal, Hyperspecral">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/DMU_64.ico">
<title>Qiang Zhang</title>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/ZQ.jpg" alt="" height="245px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Qiang Zhang (</font><font size="4"; font style="font-family:Microsoft YaHei">å¼  å¼º</font><font size="4">)</font></a><br />
<br />
 
<i>Xinghai Associate Professor</i><br />
Email: qzhang95@dlmu.edu.cn <br />
<br />

<a href="https://www.dlmu.edu.cn/" target="_blank"> Dalian Maritime University | å¤§è¿æµ·äº‹å¤§å­¦</a><br />
<a href="http://ist.dlmu.edu.cn/" target="_blank">Information Science and Technology College | ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢</a><br />
<a href="https://ist.dlmu.edu.cn/info/1099/1131.htm" target="_blank">Department of Computer Science and Technology | è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯æ•™å­¦ç³»</a><br />
<br />

Location: Jidian Building-501, Linghai Road #1, Ganjingzi, Dalian, Liaoning, China<br />
 
[<a href="https://scholar.google.com/citations?user=Hb6OKF0AAAAJ&hl=en" target="_blank">Google Scholar</a>] 
[<a href="https://github.com/qzhang95" target="_blank">GitHub</a>] 
[<a href="https://www.researchgate.net/profile/Qiang-Zhang-147" target="_blank">ResearchGate</a>] 
[<a href="https://orcid.org/0000-0002-7116-9327" target="_blank">ORCID</a>] 
[<a href="./Files/weixin.png" target="_blank"><font style="font-family:Microsoft YaHei">æ‰«ç åŠ æœ¬äººå¾®ä¿¡</font></a>] 
[<a href="https://ist.dlmu.edu.cn/info/1287/6478.htm" target="_blank"><font style="font-family:Microsoft YaHei">å­¦é™¢ä¸ªäººä¸»é¡µ</font></a>]
<br />
<class="staffshortcut">
<A HREF="#Experience">Experience</A> | 
<A HREF="#Publications">Publications</A> | 
<A HREF="#Fundings">Fundings</A> | 
<A HREF="#Teaching">Teaching</A> | 
<A HREF="#Students">Students</A> | 
<A HREF="#Services">Services</A> | 
<A HREF="#Resources">Resources</A> | 
<A HREF="#Awards">Awards</A>
<br />
 
</td></tr></table>



<A NAME="Bio"><h2>Bio</h2></A>
å¼ å¼ºï¼Œ1995å¹´ç”Ÿï¼Œè¾½å®å¤§è¿äººï¼Œå¤§è¿æµ·äº‹å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å­¦é™¢å…´æµ·å‰¯æ•™æˆï¼Œç¡•å£«ç”Ÿå¯¼å¸ˆï¼Œç ”ç©¶æ–¹å‘ä¸ºé¥æ„Ÿä¿¡æ¯å¤„ç†ã€è®¡ç®—æœºè§†è§‰ä¸æœºå™¨å­¦ä¹ ã€‚ä¸»æŒå›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®ã€ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘ç‰¹åˆ«èµ„åŠ©ã€ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®ã€è¾½å®çœåšå£«ç§‘ç ”å¯åŠ¨é¡¹ç›®ã€å¤§è¿å¸‚ç§‘æŠ€äººæ‰åˆ›æ–°é¡¹ç›®ç­‰ç§‘ç ”é¡¹ç›®ã€‚åœ¨å­¦æœ¯æœŸåˆŠä¸Šå…±å‘è¡¨è®ºæ–‡30ä½™ç¯‡ï¼Œå…¶ä¸­ä»¥ç¬¬ä¸€åŠé€šè®¯ä½œè€…åœ¨IEEE TIPã€IEEE TNNLSã€IEEE TGRSã€ISPRS P&RSã€ESSDã€ESWAã€EAAIã€JAGç­‰å›¾åƒå¤„ç†/é¥æ„Ÿ/æœºå™¨å­¦ä¹ /äººå·¥æ™ºèƒ½/åœ°å­¦é¢†åŸŸçš„é¡¶çº§æœŸåˆŠä¸Šå‘è¡¨SCIè®ºæ–‡22ç¯‡ï¼Œå«ESIçƒ­ç‚¹è®ºæ–‡1ç¯‡ï¼ŒESIé«˜è¢«å¼•è®ºæ–‡7ç¯‡ã€‚è°·æ­Œå­¦æœ¯æ€»å¼•ç”¨2500ä½™æ¬¡ï¼Œå•ç¯‡ä¸€ä½œæœ€é«˜è¢«å¼•400ä½™æ¬¡ã€‚æ‹…ä»»Remote SensingæœŸåˆŠå®¢åº§ç¼–è¾‘ã€å›½é™…åœ°å­¦ä¸é¥æ„Ÿå¤§ä¼šIGARSSåˆ†ä¼šåœºä¸»å¸­ï¼Œä»¥åŠ30ä½™ä¸ªå›½é™…æœŸåˆŠå®¡ç¨¿äººã€‚å…ˆåè£è·æå°æ–‡é¥æ„Ÿç§‘å­¦é’å¹´å¥–ã€å¤§è¿å¸‚é’å¹´ç§‘æŠ€ä¹‹æ˜Ÿã€å¤§è¿å¸‚è‡ªç„¶ç§‘å­¦äºŒç­‰å¥–ã€æ­¦æ±‰å¤§å­¦ç ”ç©¶ç”Ÿå­¦æœ¯åˆ›æ–°å¥–ç‰¹ç­‰å¥–ã€ç‹ä¹‹å“åˆ›æ–°äººæ‰ç‰¹ç­‰å¥–ã€å¤§è¿å¸‚é«˜å±‚æ¬¡å¼•è¿›äººæ‰é’å¹´æ‰ä¿Šç­‰å¥–é¡¹è£èª‰ã€‚
<br />
<br />
<br />
<p style="text-align: center"><img src="./Files/dongtu2.gif" alt="" width="20px"/><b><font size="4"; color="#FF0000"> æ‹›ç”Ÿè¯´æ˜ï¼šæ¯å¹´æ‹›æ”¶ç¡•å£«ç”Ÿ2~3åï¼Œæ¬¢è¿è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ã€æ•°å­¦ã€è½¯ä»¶å·¥ç¨‹ã€äººå·¥æ™ºèƒ½ã€æ•°æ®ç§‘å­¦ä¸å¤§æ•°æ®æŠ€æœ¯ã€æ™ºèƒ½ç§‘å­¦ä¸æŠ€æœ¯ã€é¥æ„Ÿã€åœ°ç†ä¿¡æ¯ç§‘å­¦ç­‰ä¸“ä¸šçš„åŒå­¦æŠ¥åè”ç³»ï¼æœ‰æ„æ„¿è€…è¯·æŠŠç®€å†å‘è‡³æœ¬äººé‚®ç®±ï¼ŒæœŸå¾…ä½ æˆ‘èƒ½ç›¸äº’æˆå°±ï¼</font> </b>
<li> <b><a href= "http://grs.dlmu.edu.cn/" target="_blank">å­¦ç¡•</a>ï¼š&#10173 è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ (081200)</b></li>
<li> <b><a href= "http://grs.dlmu.edu.cn/" target="_blank">ä¸“ç¡•</a>ï¼š&#10173 è®¡ç®—æœºæŠ€æœ¯ (085404)ã€&#10173 è½¯ä»¶å·¥ç¨‹ (085405)ã€&#10173 äººå·¥æ™ºèƒ½ (085410)ã€&#10173 å¤§æ•°æ®æŠ€æœ¯ä¸å·¥ç¨‹ (085411)ç­‰</b></li>
<li> <b><a href= "https://ist.dlmu.edu.cn/info/1068/4218.htm" target="_blank">å¤ä»¤è¥ä¼˜ç§€è¥å‘˜</a>ï¼šæ¨å…ç›´æ¥å½•å–, è€ƒç ”ä¼˜å…ˆå½•å–ã€‚å…¥è¥åé¢æœ‰é™, è¯·æå‰è”ç³»</b></li>
<li> <b><a href= "http://cxcy.dlmu.edu.cn/" target="_blank">å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šè®­ç»ƒè®¡åˆ’</a>ï¼šå¯¹å­¦æœ¯ç§‘ç ”æœ‰å…´è¶£çš„åœ¨æ ¡æœ¬ç§‘ç”Ÿ, æœ‰ä¸€å®šçš„æ•°å­¦ä¸ç¼–ç¨‹åŸºç¡€</b></li>
</p>
 
<br />
<br />
<p style="text-align: center"><img src="./Files/dongtu2.gif" alt="" width="20px"/><b><font size="4"> è¡¥å……è¯´æ˜ï¼šå¸ˆè€…ï¼Œæ‰€ä»¥ä¼ é“ã€æˆä¸šã€è§£æƒ‘ä¹Ÿâ€”â€”â€”â€”<font color="#FF0000">â€œè®©å­¦ç”Ÿæˆä¸ºæ›´å¥½çš„è‡ªå·±â€ï¼Œæ˜¯æˆ‘æœ¬äººå¯¹äºç ”ç©¶ç”ŸåŸ¹å…»çš„æœŸæœ›ä¸å‡†åˆ™ã€‚</font></font> </b>
<li> <b>æ‰€æŒ‡å¯¼çš„ç ”ç©¶ç”Ÿäººå‡å‘è¡¨SCIè®ºæ–‡2ç¯‡ï¼ˆåŒ…æ‹¬IEEE TNNLSã€TGRSç­‰äººå·¥æ™ºèƒ½/é¥æ„Ÿé¢†åŸŸé¡¶çº§æœŸåˆŠï¼‰ï¼Œå‚è§<A HREF="#Students">Students</A>éƒ¨åˆ†</b></li>
<li> <b>å¤šäººæ¬¡è·å¾—ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ã€ä¸“é¡¹å¥–å­¦é‡‘ã€è¾½å®çœä¼˜ç§€æ¯•ä¸šç”Ÿã€å¤§è¿å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿç­‰å¥–é¡¹è£èª‰</b>ğŸ‰ğŸ‰ğŸ‰</li>
<li> <b>æ ¹æ®ä¸ªäººå·¥ä½œé‡åŠå­¦æœ¯æˆæœå‘è¡¨æƒ…å†µï¼Œå®šæœŸå‘æ”¾å­¦ç”ŸåŠ³åŠ¡è´¹åŠå­¦æœ¯æˆæœå¥–åŠ±</b>ğŸ’°ï¸ğŸ’°ï¸ğŸ’°ï¸</li>
<li> <b>è¯¾é¢˜ç»„ä¸ææ‰“å¡ã€ä¸æå½¢å¼ä¸»ä¹‰ã€ä¸ä¹±æŠ˜è…¾ï¼Œæ•ˆç‡ç¬¬ä¸€</b>âš¡ï¸âš¡ï¸âš¡ï¸</li>
<li> <b>æ”¯æŒä¼˜ç§€ç ”ç©¶ç”Ÿåœ¨ç ”äºŒæˆ–ç ”ä¸‰æœŸé—´å‚åŠ å¤§å‚å®ä¹ </b>ğŸ‘¨ğŸ»â€ğŸ’»ğŸ‘¨ğŸ»â€ğŸ’»ğŸ‘¨ğŸ»â€ğŸ’»</li>
<li> <b>æ¯•ä¸šç”Ÿå°±ä¸šå»å‘ï¼šå¿«æ‰‹ã€æºç¨‹ã€æ¯”äºšè¿ªç­‰å•ä½</b>ğŸ­ï¸ğŸ­ï¸ğŸ­ï¸</li>
</p>
 
<br />
<br />
<p style="text-align: center"><img src="./Files/dongtu2.gif" alt="" width="20px"/><b><font size="4">ä¸“åˆŠå¾ç¨¿ï¼šRemote Sensing (IF=4.2ï¼Œä¸­ç§‘é™¢äºŒåŒº)ï¼ŒSpecial Issue: </font><font size="4"><a href= "https://www.mdpi.com/journal/remotesensing/special_issues/568Q185F7Q" target="_blank">Trends and Prospects in Hyperspectral Remote Sensing Images Processing and Analysis</a></font><font size="4">ï¼Œæˆªæ­¢æ—¶é—´ï¼š2025å¹´9æœˆ15æ—¥ï¼Œæ•¬è¯·å„ä½è€å¸ˆå’Œä¸“å®¶èµç¨¿ï¼</font></b>
</p>
<br />

<A NAME="News"><h2>News</h2></A>
<ul>
<li> <b> <font color="#FF0000">[2025.07]</font> </b> Awarded with the <b>Second Prize in Natural Science of Dalian City</b> (<a href= "https://www.dl.gov.cn/art/2025/7/9/art_852_2449903.html" target="_blank">å¤§è¿å¸‚è‡ªç„¶ç§‘å­¦äºŒç­‰å¥–</a>)!</li>
<li> <b> <font color="#FF0000">[2025.07]</font> </b> One paper for remote sensing image semantic segmentation has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10713423" target="_blank">link</a>, <a href= "https://github.com/chirsycy" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2025.07]</font> </b> One co-author paper for remote sensing image change detection has been accepted by <b>IEEE JSTARS</b> (<a href= "https://ieeexplore.ieee.org/document/11063325" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2025.06]</font> </b> One paper for SGD-SST products reconstruction and validation has been accepted by <b>ESWA</b> (<a href= "https://www.sciencedirect.com/science/article/pii/S0957417425023218" target="_blank">link</a>, <a href= "https://zenodo.org/records/14064951" target="_blank">dataset</a>)!</li>
<li> <b> <font color="#FF0000">[2025.06]</font> </b> Supported by the <b>Special Funding of China Postdoctoral Science Foundation</b> (<a href= "https://www.chinapostdoctor.org.cn/bshjjh" target="_blank">ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘ç‰¹åˆ«èµ„åŠ©</a>)!</li>
<li> <b> <font color="#FF0000">[2025.06]</font> </b> Supported by the <b>Liaoning Province Doctoral Research Startup Project</b> (<a href= "https://kjt.ln.gov.cn/kjt/tztg/gztz/2025061616311736580/index.shtml" target="_blank">è¾½å®çœåšå£«ç§‘ç ”å¯åŠ¨é¡¹ç›®</a>)!</li>
<li> <b> <font color="#FF0000">[2025.05]</font> </b> One co-author paper for hyperspectral image classification has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/11014629" target="_blank">link</a>, <a href= "https://github.com/Chirsycy/CP-Transformer" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2025.05]</font> </b> One paper for thick cloud removal has been selected as the <b>ESI Highly Cited Paper (TOP 1%)</b> !</li>
<li> <b> <font color="#FF0000">[2025.04]</font> </b> One co-author paper for seamless global daily VOD products has been accepted by <b>ESSD</b> (<a href= "https://essd.copernicus.org/articles/17/2849/2025/essd-17-2849-2025.html" target="_blank">link</a>)!</li></li>
<li> <b> <font color="#FF0000">[2025.03]</font> </b> Two conference papers for remote sensing applications have been accepted by <b>IGARSS 2025</b> (<a href= "https://2025.ieeeigarss.org/" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2025.03]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>EAAI</b> (<a href= "https://www.sciencedirect.com/science/article/pii/S0952197625005081" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2025.02]</font> </b> One co-author paper for Himawari-8/9 near real-time wildfire detection has been accepted by <b>JAG</b> (<a href= "https://www.sciencedirect.com/science/article/pii/S1569843225000639" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2025.01]</font> </b> Awarded with the <b>Outstanding Graduate of Liaoning Province</b> for Yushuai Dong (<a href= "https://ist.dlmu.edu.cn/" target="_blank">è‘£ç¾½å¸…è·è¾½å®çœä¼˜ç§€æ¯•ä¸šç”Ÿ</a>)!</li>
<li> <b> <font color="#FF0000">[2025.01]</font> </b> Awarded with the <b>Outstanding Graduate of Dalian City</b> for Yaming Zheng (<a href= "https://ist.dlmu.edu.cn/" target="_blank">éƒ‘äºšæ˜è·å¤§è¿å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿ</a>)!</li>
<li> <b> <font color="#FF0000">[2025.01]</font> </b> Awarded with the <b>Outstanding Graduate of DMU</b> for Jian Zhu (<a href= "https://ist.dlmu.edu.cn/" target="_blank">æœ±å¥è·å¤§è¿æµ·äº‹å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</a>)!</li>
<li> <b> <font color="#FF0000">[2024.12]</font> </b> Publications in Google Scholar have been cited over <b>2000 times</b> (<a href= "https://scholar.google.com/citations?user=Hb6OKF0AAAAJ&hl=zh-CN" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.12]</font> </b> One paper for 10-minute forest early wildfire detection has been accepted by <b>Neurocomputing</b> (<a href= "https://www.sciencedirect.com/science/article/abs/pii/S092523122401734X?via%3Dihub" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.11]</font> </b> Awarded with the <b>Youth Science and Technology Star of Dalian City</b> (<a href= "https://kjj.dl.gov.cn/art/2024/11/4/art_4901_2355824.html" target="_blank">å¤§è¿å¸‚é’å¹´ç§‘æŠ€ä¹‹æ˜Ÿ</a>)!</li>
<li> <b> <font color="#FF0000">[2024.11]</font> </b> Awarded with the <b>National Scholarship for Graduate Student</b> Yushuai Dong (<a href= "https://ist.dlmu.edu.cn/" target="_blank">è‘£ç¾½å¸…è·ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘</a>)!</li>
<li> <b> <font color="#FF0000">[2023.11]</font> </b> Attended the National Symposium on <b>Spectral Imaging and Earth Observation</b> in Shanghai (<a href= "https://hsi.ecnu.edu.cn/" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.10]</font> </b> One paper for remote sensing image change detection has been accepted by <b>IEEE GRSL</b> (<a href= "https://ieeexplore.ieee.org/document/10713423" target="_blank">link</a>, <a href= "https://github.com/chirsycy/FTAN" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2024.09]</font> </b> Served as the <b>Leading Guest Editor</b> of Remote Sensing (<a href= "https://www.mdpi.com/journal/remotesensing/special_issues/568Q185F7Q" target="_blank">Special Issue</a>)!</li>
<li> <b> <font color="#FF0000">[2024.09]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10677534" target="_blank">link</a>, <a href= "https://github.com/Featherrain/TDSAT" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2024.09]</font> </b> One co-author paper for remote sensing image super-resolution has been accepted by <b>IEEE TMM</b> (<a href= "https://xy-boy.github.io" target="_blank">link</a>, <a href= "https://github.com/XY-boy/FreMamba" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2024.08]</font> </b> Supported by the <b>Youth Project of National Natural Science Foundation of China</b> (<a href= "https://www.nsfc.gov.cn" target="_blank">å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®</a>)!</li>
<li> <b> <font color="#FF0000">[2024.08]</font> </b> One paper for hyperspectral image classification has been accepted by <b>IEEE GRSL</b> (<a href= "https://ieeexplore.ieee.org/document/10659630" target="_blank">link</a>, <a href= "https://github.com/Chirsycy/DICMA" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2024.07]</font> </b> One paper for hyperspectral wheat variety identification has been selected as the <b>ESI Hot Paper (TOP 0.1%)</b> !</li>
<li> <b> <font color="#FF0000">[2024.07]</font> </b> Two papers for hyperspectral image denoising have been selected as the <b>ESI Highly Cited Paper (TOP 1%)</b> !</li>
<li> <b> <font color="#FF0000">[2024.06]</font> </b> One co-author paper for hyperspectral image classification has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10574887" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.05]</font> </b> One paper for hyperspectral image denoising has been selected as the <b>ESI Highly Cited Paper (TOP 1%)</b> !</li>
<li> <b> <font color="#FF0000">[2024.04]</font> </b> One co-author paper for land surface temperature retrieval has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10505162" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.04]</font> </b> One co-author paper for hyperspectral image non-blind deblurring has been accepted by <b>IEEE TCSVT</b> (<a href= "https://ieeexplore.ieee.org/document/10493191" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.03]</font> </b> Three conference papers for remote sensing image processing have been accepted by <b>IGARSS 2024</b> (<a href= "https://2024.ieeeigarss.org" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.02]</font> </b> One paper for hyperspectral image anomaly detection has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10430170" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.01]</font> </b> One co-author paper for hyperspectral wheat variety identification has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10375525" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.12]</font> </b> Supported by the <b>General Project of China Postdoctoral Science Foundation</b> (<a href= "https://www.chinapostdoctor.org.cn/bshjjh" target="_blank">ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®</a>)!</li>
<li> <b> <font color="#FF0000">[2023.11]</font> </b> Attended the National Symposium on <b>Spectral Imaging and Earth Observation</b> in Guangzhou (<a href= "https://geo.gzhu.edu.cn/info/1122/5253.htm" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.10]</font> </b> Awarded with the <b>Special Scholarship</b> for Graduate Student Yaming Zheng (<a href= "https://ist.dlmu.edu.cn/" target="_blank">éƒ‘äºšæ˜è·æ‹›å•†è½®èˆ¹å¥–å­¦é‡‘</a>)!</li>
<li> <b> <font color="#FF0000">[2023.10]</font> </b> One paper for Himawari-8 early-stage wildfire detection has been accepted by <b>JAG</b> (<a href= "https://www.sciencedirect.com/science/article/pii/S1569843223003308" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.09]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10262064" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.08]</font> </b> One co-author paper for hyperspectral image classification has been accepted by <b>IEEE GRSL</b> (<a href= "https://ieeexplore.ieee.org/document/10210340" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.07]</font> </b> One co-author paper for satellite video super-resolution has been accepted by <b>IEEE TGRS</b> (<a href= "https://ieeexplore.ieee.org/document/10172076" target="_blank">link</a>, <a href= "https://github.com/XY-boy/Blind-Satellite-VSR" target="_blank">code</a>)!</li>
<li> <b> <font color="#FF0000">[2023.06]</font> </b> Attended the Vision And Learning SEminar (<b>VALSE 2023</b>) in Wuxi (<a href= "http://valser.org/2023/#/" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.05]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>IEEE TNNLS</b> (<a href= "https://ieeexplore.ieee.org/document/10144690" target="_blank">link</a>, <a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">dataset</a>)!</li>
<li> <b> <font color="#FF0000">[2023.04]</font> </b> One conference paper for Himawari-8 early wildfire detection has been accepted by <b>IGARSS 2023</b> (<a href= "https://2023.ieeeigarss.org" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.03]</font> </b> One paper for satellite video super-resolution has been selected as the <b>ESI Highly Cited Paper (TOP 1%)</b> !</li>
<li> <b> <font color="#FF0000">[2023.02]</font> </b> Publications in Google Scholar have been cited over <b>1000 times</b> (<a href= "https://scholar.google.com/citations?user=Hb6OKF0AAAAJ&hl=zh-CN" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.01]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>IEEE GRSL</b> (<a href= "https://ieeexplore.ieee.org/document/10015865" target="_blank">link</a>, <a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">dataset</a>)!</li>
<li> <b> <font color="#FF0000">[2022.12]</font> </b> Awarded with the <b>Youth Talent of Dalian City High-level Talent</b> (<a href= "https://www.dl-rc.com/" target="_blank">å¤§è¿å¸‚é«˜å±‚æ¬¡å¼•è¿›äººæ‰é’å¹´æ‰ä¿Š</a>)!</li>
<li> <b> <font color="#FF0000">[2022.11]</font> </b> One co-author paper for hyperspectral corn variety identification has been accepted by <b>IEEE GRSL</b> (<a href= "https://ieeexplore.ieee.org/document/9964375" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2022.10]</font> </b> One paper for hyperspectral image denoising has been accepted by <b>IEEE TIP</b> (<a href= "https://ieeexplore.ieee.org/document/9913829" target="_blank">link</a>, <a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">dataset</a>, <a href= "http://news.dlmu.edu.cn/info/1003/27425.htm" target="_blank">news</a>)!</li>
<li> <b> <font color="#FF0000">[2022.09]</font> </b> One paper for seamless global daily soil moisture products has been accepted by <b>ESSD</b> (<a href= "https://essd.copernicus.org/articles/14/4473/2022/" target="_blank">link</a>, <a href= "https://doi.org/10.5281/zenodo.6041561" target="_blank">dataset</a>, <a href= "https://github.com/qzhang95/SGD-SM" target="_blank">code</a>)!</li></li>
</ul>
<br />



<A NAME="Topic"><h2>Research Topic</h2></A>
<ul>
<li><b>Remote Sensing Information Processing</b> (<a href="https://baike.baidu.com/item/é¥æ„Ÿä¿¡æ¯å¤„ç†/9256797?fr=aladdin" target="_blank">é¥æ„Ÿä¿¡æ¯å¤„ç†</a>): Hyperspectral/Multitemporal/Ocean Remote Sensing</li>
<li><b>Computer Vision</b> (<a href="https://baike.baidu.com/item/è®¡ç®—æœºè§†è§‰/2803351?fr=aladdin" target="_blank">è®¡ç®—æœºè§†è§‰</a>): Image Denoising/Enhancement/Fusion/Super-Resolution, Low-level Vision</li>
<li><b>Machine Learning</b> (<a href="https://baike.baidu.com/item/æœºå™¨å­¦ä¹ /217599?fr=aladdin" target="_blank">æœºå™¨å­¦ä¹ </a>): Deep Learning, Low-Rank Tensor Representation, Model-Data-Driven</li>
</ul>
<br />


 
<A NAME="Experience"><h2>Experience</h2></A>
<p><b>Work Experience</b>: </p>
<font size="3"> 
<ul>
<li>2023.08-Now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Parttime Postdoctor, <a href="https://rcb.dlmu.edu.cn/info/1026/1341.htm" target="_blank">Postdoctoral Station in Computer Science</a>, <a href="http://www.dlmu.edu.cn/" target="_blank">Dalian Maritime University</a></li>
<li>2022.07-Now &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Xinghai Associate Professor, <a href="http://ist.dlmu.edu.cn/" target="_blank">Information Science and Technology College</a>, <a href="http://www.dlmu.edu.cn/" target="_blank">Dalian Maritime University</a></li>
</font>
</ul>
<br />
<br />
<br />
 
<p><b>Education Experience</b>: </p>
<font size="3"> 
<ul>
<li>2019.09-2022.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D in <a href="http://www.lmars.whu.edu.cn/" target="_blank">LIESMARS</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html" target="_blank">Liangpei Zhang</a> & <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a></li>
<li>2017.09-2019.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; M.E. in <a href="http://main.sgg.whu.edu.cn/" target="_blank">School of Geodesy and Geomatics</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a></li>
<li>2013.09-2017.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.E. in <a href="http://main.sgg.whu.edu.cn/" target="_blank">School of Geodesy and Geomatics</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="http://qqyuan.users.sgg.whu.edu.cn/" target="_blank">Qiangqiang Yuan</a></li>
</ul>
</font>
<br />

<!-- Impact Factor List -->
<script>
var citation=2500;
isprsif=12.2;
tipif=13.7;
essdif=11.6;
tmmif=9.7;
tcsvtif=11.1;
tnnlsif=8.9;
tgrsif=8.6;
jagif=8.6;
eaaiif=8;
eswaif=7.5;
jstarsif=5.3;
grslif=4.4;
rsif=4.1;
ncif=6.5;
</script> 


<A NAME="Publications"><h2>Publications [Citations: <font color="#FF0000">2500+</font>]</h2></A>
<p><b>Journals</b>: (<b>*</b> denotes the Corresponding Author)</p>
<font size="3"> 
<ul>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[36] Q. Wang, <b>Q. Zhang*</b>, H. Xie, Z. Liu, and Y. Dong, 
â€œSGD-SST: Seamless global daily sea surface temperature products reconstruction and validation via deep spatio-temporal fusion model,â€ 
<i>Expert Systems with Applications (<b>ESWA</b>)</i>, 
vol. 263, 128703, 2025. 
(<b>SCI Q1 Top, IF=<script>document.write(eswaif)</script></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0957417425023218" target="_blank">Link</a>] 
[<a href= "./Files/ESWA_2025_SGD-SST.pdf" target="_blank">PDF</a>]  
[<a href= "https://zenodo.org/records/14064951" target="_blank">Dataset</a>] 
[<a href="./Files/BibTeX.html#zhang2023_TNNLS" target="_blank">BibTeX</a>]
</span>
</p> 

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[35] C. Yu, Y. Zuo, <b>Q. Zhang*</b>, and Y. Wang, 
â€œProbability-guided edge enhancement network for semantic segmentation of remote sensing image,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol.63, in press, 2025.
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>)  
[<a href= "https://ieeexplore.ieee.org/document/10677534" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_TDSAT.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/Featherrain/TDSAT" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#zhang2024_TDSAT" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[34] <b>Q. Zhang</b>, Y. Zheng, Y. Dong, C. Yu, and Q. Yuan,
â€œHyperspectral image mixed noised removal via jointly spatial and spectral difference constraint with low-rank tensor factorization,â€ 
<i>Engineering Applications of Artificial Intelligence (<b>EAAI</b>)</i>, 
vol. 149, 110508, 2025. 
(<b>SCI Q1 Top, IF=<script>document.write(eaaiif)</script></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0952197625005081" target="_blank">Link</a>] 
[<a href= "./Files/EAAI_2025_JSSDC-LRTF.pdf" target="_blank">PDF</a>]  
[<a href="./Files/BibTeX.html#zhang2023_TNNLS" target="_blank">BibTeX</a>]
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[33] <b>Q. Zhang</b>, J. Zhu, Y. Dong, E. Zhao, M. Song, and Q. Yuan, 
â€œ10-minute forest early wildfire detection: Fusing multi-type and multi-source information via recursive transformer,â€ 
<i><b>Neurocomputing</b></i>, 
vol. 616, 128963, 2025.
(<b>SCI Q1, IF=<script>document.write(ncif)</script></b>)  
[<a href= "https://www.sciencedirect.com/science/article/abs/pii/S092523122401734X?via%3Dihub" target="_blank">Link</a>] 
[<a href= "./Files/NC_2025_WILDFIRE.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#zhang2024_TDSAT" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[32] <b>Q. Zhang</b>, Y. Zheng, Q. Yuan, M. Song, H. Yu, and Y. Xiao,
â€œHyperspectral image denoising: From model-driven, data-driven, to model-data-driven,â€ 
<i>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</i>, 
vol. 35, no. 10, pp. 13143-13163, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tnnlsif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10144690" target="_blank">Link</a>] 
[<a href= "./Files/TNNLS_2023_HSI.pdf" target="_blank">PDF</a>]  
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2023_TNNLS" target="_blank">BibTeX</a>]
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[31] <b>Q. Zhang</b>, Y. Dong, Y. Zheng, H. Yu, M. Song, L. Zhang, and Q. Yuan, 
â€œThree-dimension spatial-spectral attention transformer for hyperspectral image denoising,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol.62, pp. 1-13, 2024.
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>)  
[<a href= "https://ieeexplore.ieee.org/document/10677534" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_TDSAT.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/Featherrain/TDSAT" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#zhang2024_TDSAT" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[30] L. Li, <b>Q. Zhang*</b>, M. Song, and Chein-I Chang, 
â€œFeedback band group and variation low rank sparse model for hyperspectral image anomaly detection,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol.62, pp. 1-19, 2024.
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>)  
[<a href= "https://ieeexplore.ieee.org/document/10430170" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_Li.pdf" target="_blank">PDF</a>]  
[<a href="./Files/BibTeX.html#li2024_Feedback" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[29] C. Yu, M. Xu, <b>Q. Zhang*</b>, and X. Lu, 
â€œDual intervention constrained mask-adversary framework for unsupervised domain adaptation of hyperspectral image classification,â€ 
<i>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 
vol. 21, pp. 1-5, 2024. 
(<b>SCI Q1, IF=<script>document.write(grslif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10659630" target="_blank">Link</a>] 
[<a href= "./Files/GRSL_2023_DPLRTF.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/Chirsycy/DICMA" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#zhang2023_DPLRTF" target="_blank">BibTeX</a>]
</span>
</p> 

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[28] C. Yu, H. Li, Y. Hu, <b>Q. Zhang*</b>, M. Song, and Y. Wang, 
â€œFrequency-temporal attention network for remote sensing imagery change detection,â€ 
<i>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 
vol. 21, pp. 1-5, 2024. 
(<b>SCI Q1, IF=<script>document.write(grslif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10713423" target="_blank">Link</a>] 
[<a href= "./Files/GRSL_2023_DPLRTF.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/chirsycy/FTAN" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#zhang2023_DPLRTF" target="_blank">BibTeX</a>]
</span>
</p>  
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[27] L. Li, M. Song, <b>Q. Zhang*</b>, and Y. Dong, 
â€œHyperspectral denoising via global variation and local structure low-rank model,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 61, pp. 1-14, 2023. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10262064" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2023_Li.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTeX.html#li2023_GLLR" target="_blank">BibTeX</a>] 
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[26] <b>Q. Zhang</b>, J. Zhu, Y. Huang, Q. Yuan, and L. Zhang,
â€œBeyond being wise after the event: Combining spatial, temporal and spectral information for Himawari-8 early-stage wildfire detection,â€ 
<i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i>, 
vol. 124, 103506, 2023. 
(<b>SCI Q1 Top, IF=<script>document.write(jagif)</script></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S1569843223003308" target="_blank">Link</a>] 
[<a href= "./Files/JAG_2023_STSRNN.pdf" target="_blank">PDF</a>]  
[<a href="./Files/BibTeX.html#zhang2023_STSRNN" target="_blank">BibTeX</a>]
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[25] <b>Q. Zhang</b>, Y. Dong, Q. Yuan, M. Song, and H. Yu, 
â€œCombined deep priors with low-rank tensor factorization for hyperspectral image restoration,â€ 
<i>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 
vol. 20, pp. 1-5, 2023. 
(<b>SCI Q1, IF=<script>document.write(grslif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10015865" target="_blank">Link</a>] 
[<a href= "./Files/GRSL_2023_DPLRTF.pdf" target="_blank">PDF</a>] 
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2023_DPLRTF" target="_blank">BibTeX</a>]
</span>
</p> 

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[24] <b>Q. Zhang</b>, Q. Yuan, M. Song, H. Yu, and L. Zhang, 
â€œCooperated spectral low-rankness prior and deep spatial prior for HSI unsupervised denoising,â€ 
<i>IEEE Transactions on Image Processing (<b>TIP</b>)</i>, 
vol. 31, pp. 6356-6368, 2022. 
(<b><font color="#FF0000">CCF-A</font>, SCI Q1 Top, IF=<script>document.write(tipif)</script></b>) 
[<a href= "http://news.dlmu.edu.cn/info/1003/27425.htm" target="_blank">News</a>] 
[<a href= "https://ieeexplore.ieee.org/document/9913829" target="_blank">Link</a>] 
[<a href= "./Files/TIP_2022_SLRP-DSP.pdf" target="_blank">PDF</a>] 
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2022_SLRP-DSP" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[23] <b>Q. Zhang</b>, Q. Yuan, T. Jin, M. Song, and F. Sun, 
â€œSGD-SM 2.0: an improved seamless global daily soil moisture long-term dataset from 2002 to 2022,â€ 
<i>Earth System Science Data (<b>ESSD</b>)</i>, 
vol. 14, pp. 4473â€“4488, 2022. 
(<b>SCI Q1 Top, IF=<script>document.write(essdif)</script></b>) 
[<a href= "https://essd.copernicus.org/articles/14/4473/2022/" target="_blank">Link</a>] 
[<a href= "./Files/ESSD_2022_SGD-SM2.0.pdf" target="_blank">PDF</a>] 
[<a href= "https://doi.org/10.5281/zenodo.6041561" target="_blank">Dataset</a>]
[<a href="https://github.com/qzhang95/SGD-SM" target="_blank">Code</a>]
[<a href="./Files/BibTeX.html#zhang2022_SGDSM2" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[22] <b>Q. Zhang</b>, Q. Yuan, J. Li, Y. Wang, F. Sun, and L. Zhang, 
â€œGenerating seamless global daily AMSR2 soil moisture (SGD-SM) long-term products for the years 2013-2019,â€ 
<i>Earth System Science Data (<b>ESSD</b>)</i>, 
vol. 13, pp. 1385-1401, 2021. 
(<b>SCI Q1 Top, IF=<script>document.write(essdif)</script></b>) 
[<a href= "https://essd.copernicus.org/articles/13/1385/2021/" target="_blank">Link</a>] 
[<a href= "./Files/ESSD_2021_SGD-SM.pdf" target="_blank">PDF</a>] 
[<a href= "https://qzhang95.github.io/Projects/Global-Daily-Seamless-AMSR2/" target="_blank">Project</a>]
[<a href= "https://doi.org/10.5281/zenodo.4417458" target="_blank">Dataset</a>]
[<a href="https://github.com/qzhang95/SGD-SM" target="_blank">Code</a>]
[<a href="./Files/BibTeX.html#zhang2021_SGDSM" target="_blank">BibTeX</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[21] <b>Q. Zhang</b>, Q. Yuan, Z. Li, F. Sun, and L. Zhang, 
â€œCombined deep prior with low-rank tensor SVD for thick cloud removal in multitemporal images,â€ 
<i>ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>)</i>,  
vol. 177, pp. 161-173, 2021. 
(<b>SCI Q1 Top, IF=<script>document.write(isprsif)</script></b>)
[<a href= "https://www.sciencedirect.com/science/article/pii/S0924271621001258" target="_blank">Link</a>] 
[<a href= "https://wwa.lanzoui.com/if3Brpelk4j" target="_blank">PDF</a>] 
[<a href= "https://drive.google.com/file/d/1LlvUKtUWAKoF6R0igbREwvP2Wfja9UBv/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2021_DPLRTSVD" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[20] <b>Q. Zhang</b>, Q. Yuan, J. Li, F. Sun, and L. Zhang, 
â€œDeep spatio-spectral Bayesian posterior for hyperspectral image non-i.i.d. noise removal,â€ 
<i>ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>)</i>, 
vol. 164, pp. 125-137, 2020. 
(<b>SCI Q1 Top, IF=<script>document.write(isprsif)</script></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0924271620301076" target="_blank">Link</a>] 
[<a href= "./Files/ISPRS_2020_DSSBP.pdf" target="_blank">PDF</a>] 
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2020_DSSBP" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[19] <b>Q. Zhang</b>, Q. Yuan, J. Li, Z. Li, H. Shen, and L. Zhang, 
â€œThick cloud and cloud shadow removal in multitemporal images using progressively spatio-temporal patch group deep learning,â€ 
<i>ISPRS Journal of Photogrammetry and Remote Sensing (<b>ISPRS P&RS</b>)</i>, 
vol. 162, pp. 148-160, 2020. 
(<b>SCI Q1 Top, IF=<script>document.write(isprsif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0924271620300423" target="_blank">Link</a>] 
[<a href= "./Files/ISPRS_2020_PSTCR.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/qzhang95/PSTCR" target="_blank">Code</a>]
[<a href= "https://drive.google.com/file/d/1LlvUKtUWAKoF6R0igbREwvP2Wfja9UBv/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2020_PSTCR" target="_blank">BibTeX</a>]
[Citations: <b>100</b>+]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[18] <b>Q. Zhang</b>, Q. Yuan, J. Li, X. Liu, H. Shen, and L. Zhang, 
â€œHybrid noise removal in hyperspectral imagery with spatial-spectral gradient network,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 57, no. 10, pp. 7317-7329, 2019. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/8734833" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2019_SSGN.pdf" target="_blank">PDF</a>]
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>]
[<a href="./Files/BibTeX.html#zhang2019_SSGN" target="_blank">BibTeX</a>] 
[Citations: <b>100</b>+] 
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[17] <b>Q. Zhang</b>, Q. Yuan, C. Zeng, X. Li, and Y. Wei, 
â€œMissing data reconstruction in remote sensing image with a unified spatial-temporal-spectral deep convolutional neural network,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 56, no. 8, pp. 4274-4288, 2018. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b>) 
[<a href= "https://ieeexplore.ieee.org/document/8316243" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2018_STS-CNN.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/qzhang95/STS-CNN" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#zhang2018_STS" target="_blank">BibTeX</a>] 
[Citations: <b>400</b>+]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[16] <b>Q. Zhang</b>, Q. Yuan, J. Li, Z. Yang, and X. Ma, 
â€œLearning a dilated residual network for SAR image despeckling,â€ 
<i>Remote Sensing (<b>RS</b>)</i>, 
vol. 10, no. 2, 196, 2018. 
(<b>SCI Q1, IF=<script>document.write(rsif)</script></b>) 
[<a href= "https://www.mdpi.com/2072-4292/10/2/196" target="_blank">Link</a>] 
[<a href= "./Files/RS_2018_SAR-DRN.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTeX.html#zhang2018_SAR" target="_blank">BibTeX</a>]
[Citations: <b>200</b>+]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[15] Q. Yuan, <b>Q. Zhang</b>, J. Li, H. Shen, and L. Zhang, 
â€œHyperspectral image denoising employing a spatial-spectral deep residual convolutional neural network,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 57, no. 2, pp. 1205-1218, 2019. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b>) 
[<a href= "https://ieeexplore.ieee.org/document/8454887" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2019_HSID-CNN.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/qzhang95/HSID-CNN" target="_blank">Code</a>] 
[<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>] 
[<a href="./Files/BibTeX.html#yuan2019_HSID" target="_blank">BibTeX</a>] 
[Citations: <b>400</b>+]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[14] L. Zhang, <b>Q. Zhang</b>, Q. Yang, L. Yue, J. He, X. Jin, and Q. Yuan,
â€œNear-real-time wildfire detection approach with Himawari-8/9 geostationary satellite data integrating multi-scale spatialâ€“temporal feature,â€ 
<i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i>, 
vol. 137, 104416, 2025. 
(<b>SCI Q1 Top, IF=<script>document.write(jagif)</script></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S1569843225000639" target="_blank">Link</a>] 
[<a href= "./Files/JAG_2023_STSRNN.pdf" target="_blank">PDF</a>]  
[<a href="./Files/BibTeX.html#zhang2023_STSRNN" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[13] C. Yu, Y. Zhu, Y. Wang, E, Zhao, <b>Q. Zhang</b>, and X. Lu,
â€œConcern with center-pixel labeling: Center-specific perception transformer network for hyperspectral image classification,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 63, 5514614, 2025. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/11014629" target="_blank">Link</a>] 
[<a href= "./Files/JAG_2023_STSRNN.pdf" target="_blank">PDF</a>]  
[<a href="./Files/BibTeX.html#zhang2023_STSRNN" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[12] D. Hu, Y. Wang, H. Jing, L.Yue, <b>Q. Zhang</b>, L. Fan, Q. Yuan, H. Shen, and L. Zhang, 
â€œA global daily seamless 9-km vegetation optical depth (VOD) product from 2010 to 2021,â€ 
<i>Earth System Science Data (<b>ESSD</b>)</i>, 
vol. 17, pp. 2849â€“2872, 2025. 
(<b>SCI Q1 Top, IF=<script>document.write(essdif)</script></b>) 
[<a href= "https://essd.copernicus.org/articles/17/2849/2025/essd-17-2849-2025.html" target="_blank">Link</a>] 
[<a href= "./Files/ESSD_2022_SGD-SM2.0.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#zhang2022_SGDSM2" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[11] C. Yu, C. Yu, F. Zhou, Y. Wang, and <b>Q. Zhang</b>, 
â€œEn-decoded index guided edge refinement network for change detection of remote sensing image,â€ 
<i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>)</i>, 
vol. 18, pp. 1â€“14, 2025. 
(<b>SCI Q1, IF=<script>document.write(jstarsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/11063325" target="_blank">Link</a>] 
[<a href= "./Files/ESSD_2022_SGD-SM2.0.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#zhang2022_SGDSM2" target="_blank">BibTeX</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[10] L. Li, M. Song, <b>Q. Zhang</b>, Y. Dong, Y. Wang, and Q. Yuan,  
â€œLocal extremum constrained total variation model for natural and hyperspectral image non-blind deblurring,â€ 
<i>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>)</i>, 
vol. 61, pp. 1-16, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tcsvtif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10262064" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2023_Li.pdf" target="_blank">PDF</a>]
[<a href="./Files/BibTeX.html#li2023_GLLR" target="_blank">BibTeX</a>] 
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[09] Y. Xiao, Q. Yuan, K. Jiang, Y. Chen, <b>Q. Zhang</b>, and CW. Lin, 
â€œfrequency-assisted mamba for remote sensing image super-resolution,â€ 
<i>IEEE Transactions on Multimedia (<b>TMM</b>)</i>, 
vol. 26, pp. 1-13, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tmmif)</script></b>) 
[<a href= "https://arxiv.org/abs/2405.04964" target="_blank">Link</a>] 
[<a href= "https://arxiv.org/abs/2405.04964" target="_blank">PDF</a>] 
[<a href="https://github.com/XY-boy/FreMamba" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#lin2022_RTCR" target="_blank">BibTeX</a>] 
</span>
</p> 

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[08] C. Yu, Y. Zhu, M. Song, Y. Wang, and <b>Q. Zhang</b>, 
â€œUnseen feature extraction: Spatial mapping expansion with spectral compression network for hyperspectral image classification,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 62, pp. 1-14, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10574887" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_RTCR.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#lin2022_RTCR" target="_blank">BibTeX</a>] 
</span>
</p> 

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[07] W. Zhang, Z. li, G. Li, P. Zhuang, G. Hou, <b>Q. Zhang</b>, and C. Li, 
â€œGACNet: Generate adversarial-driven cross-aware network for hyperspectral wheat variety identification,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 62, pp. 1-15, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script>, <font color="#FF0000">ESI Hot Paper</font>, <font color="#FF0000">ESI Highly Cited Paper</font></b></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10375525" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_RTCR.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#lin2022_RTCR" target="_blank">BibTeX</a>] 
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[06] E. Zhao, N. Qu, Y. Wang, C. Gao, S. Duan, J. Zeng, and <b>Q. Zhang</b>, 
â€œThermal infrared hyperspectral band selection via graph neural network for land surface temperature retrieval,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 62, pp. 1-15, 2024. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10505162" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2024_RTCR.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#lin2022_RTCR" target="_blank">BibTeX</a>] 
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[05] Y. Xiao, Q. Yuan, <b>Q. Zhang</b>, and L. Zhang, 
â€œDeep blind super-resolution for satellite video,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 61, pp. 1-16, 2023. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b></b>) 
[<a href= "https://ieeexplore.ieee.org/abstract/document/10172076" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2023_BSVSR.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/XY-boy/Blind-Satellite-VSR" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#xiao2023_BSVSR" target="_blank">BibTeX</a>] 
</span>
</p> 

 <p style="text-indent: -2rem;margin-left: 0rem;">
<span>[04] H. Yang, H. Yu, K. Zheng, J. Hu, T. Tao, and <b>Q. Zhang</b>, 
â€œHyperspectral image classification based on interactive transformer and CNN with multilevel feature fusion network,â€ 
<i>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 
vol. 20, pp. 1-5, 2023. 
(<b>SCI Q1, IF=<script>document.write(grslif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/10210340" target="_blank">Link</a>] 
[<a href= "./Files/GRSL_2023_Yuhaoyang.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#yu2023" target="_blank">BibTeX</a>] 
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[03] Y. Xiao, Q. Yuan, J. He, <b>Q. Zhang</b>, J. Sun, X. Su, J. Wu and L. Zhang, 
â€œSpace-time super-resolution for satellite video: A joint framework based on multi-scale spatial-temporal transformer,â€ 
<i>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</i>, 
vol. 108, 102731, 2022. 
(<b>SCI Q1 Top, IF=<script>document.write(jagif)</script>, <font color="#FF0000">ESI Highly Cited Paper</font></b>) 
[<a href= "https://www.sciencedirect.com/science/article/pii/S0303243422000575" target="_blank">Link</a>] 
[<a href= "./Files/JAG_2022_MSTT.pdf" target="_blank">PDF</a>] 
[<a href="https://github.com/XY-boy/MSTT-STVSR" target="_blank">Code</a>] 
[<a href="./Files/BibTeX.html#xiao2022_MSTT" target="_blank">BibTeX</a>] 
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[02] W. Zhang, Z. Li, H. Sun, <b>Q. Zhang</b>, P. Zhuang, and C. Li, 
â€œSSTNet: Spatial, spectral, and texture aware attention network using hyperspectral image for corn variety identification,â€ 
<i>IEEE Geoscience and Remote Sensing Letters (<b>GRSL</b>)</i>, 
vol. 19, pp. 1-5, 2022. 
(<b>SCI Q1, IF=<script>document.write(grslif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/9964375" target="_blank">Link</a>] 
[<a href= "./Files/GRSL_2022_SSTNet.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#zhang2022_SSTNet" target="_blank">BibTeX</a>] 
</span>
</p> 
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[01] J. Lin, T. Huang, X. Zhao, Y. Chen, <b>Q. Zhang</b>, and Q. Yuan, 
â€œRobust thick cloud removal for multi-temporal remote sensing images using coupled tensor factorization,â€ 
<i>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</i>, 
vol. 60, pp. 1-16, 2022. 
(<b>SCI Q1 Top, IF=<script>document.write(tgrsif)</script></b>) 
[<a href= "https://ieeexplore.ieee.org/document/9672204" target="_blank">Link</a>] 
[<a href= "./Files/TGRS_2022_RTCR.pdf" target="_blank">PDF</a>] 
[<a href="./Files/BibTeX.html#lin2022_RTCR" target="_blank">BibTeX</a>] 
</span>
</p> 
</ul>
</font>
<br />
<br />
<br />

 
 
<p><b>Conferences</b>: </p>
<font size="3"> 
<ul>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[10] Z. Liu, <b>Q. Zhang*</b>, Q. Wang, and Y. Zheng, 
â€œValidation of Himawari-8 10-minute wildfire products: Compared with polar-orbiting satellites in long time series,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Brisbane, Australia, 2025. 
(<b>EI, Poster</b>) 
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[09] Q. Wang, <b>Q. Zhang*</b>, Z. Liu, and Y. Zheng, 
â€œGenerating global seamless sea surface temperature products from 2013 to 2024,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Brisbane, Australia, 2025. 
(<b>EI, Poster</b>) 
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[08] J. Zhu, <b>Q. Zhang*</b>, and Y. Zheng, 
â€œForest early wildfire detection via multi-source and multi-type information fusion,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Athens, Greece, 2024. 
(<b>EI, Poster</b>) 
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[07] <b>Q. Zhang</b>, and J. Zhu, 
â€œEarly wildfire detection based on temporal, spatial and spectral information fusion,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Pasadena, USA, 2023. 
(<b>EI, Poster</b>) 
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[06] <b>Q. Zhang</b>, F. Sun, Q. Yuan, and L. Zhang, 
â€œThick cloud removal for Sentinel-2 time-series images via combining deep prior and low-rank tensor completion,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Brussels, Belgium, pp. 2675-2678, 2021. 
(<b>EI, <font color="#FF0000">Oral</font></b>) 
[<a href="./Files/Qiang Zhang_Slides_IGARSS2021.pdf" target="_blank">Slides</a>]
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[05] <b>Q. Zhang</b>, F. Sun, Q. Yuan, J. Li, H. Shen, and L. Zhang, 
â€œCombined the data-driven with model-driven stragegy: A novel framework for mixed noise removal in hyperspectral image,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Hawaii, USA, pp. 2667-2670, 2020. 
(<b>EI, <font color="#FF0000">Oral</font></b>) 
[<a href="./Files/Qiang Zhang_Slides_IGARSS2020.pdf" target="_blank">Slides</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[04] <b>Q. Zhang</b>, Q. Yuan, J. Li, H. Shen, and L. Zhang, 
â€œCloud and shadow removal for Sentinel-2 by progressively spatiotemporal patch group learning,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Yakohama, Japan, pp. 775-778, 2019. 
(<b>EI, <font color="#FF0000">Oral</font></b>) 
[<a href="./Files/Qiang Zhang_Slides_IGARSS2019.pdf" target="_blank">Slides</a>]
</span>
</p>


<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[03] <b>Q. Zhang</b>, Q. Yuan, H. Shen, and L. Zhang, 
â€œA unified spatial-temporal-spectral learning framework for reconstructing missing data in remote sensing images,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Valencia, Spain, pp. 4981-4984, 2018. 
(<b>EI, Poster</b>) 
[<a href="./Files/Qiang Zhang_Slides_IGARSS2018.pdf" target="_blank">Slides</a>]
</span>
</p>

<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[02] Y. Zhu, C. Yu, M. Song, Y. Wang, E. Zhao, H. Yu, and <b>Q. Zhang</b>, 
â€œCenter category focusing transformer network for hyperspectral image classification,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Athens, Greece, 2024. 
(<b>EI, Poster</b>) 
</span>
</p>
 
<p style="text-indent: -2rem;margin-left: 0rem;">
<span>[01] Y. Yang, Y. Wang, E. Zhao, M. Song, and <b>Q. Zhang</b>, 
â€œA SWIN transformer-based fusion approach for hyperspectral image super-resolution,â€ 
<i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>)</i>, 
in Pasadena, USA, 2023. 
(<b>EI, Poster</b>) 
</span>
</p> 
</ul>
<br />

 
 

<A NAME="Fundings"><h2>Fundings</h2></A>
<font size="3"> 
<ul>
<li><b>å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘é’å¹´é¡¹ç›®</b>, æ•°æ¨¡è”åˆé©±åŠ¨çš„å›½äº§é«˜å…‰è°±å«æ˜Ÿå½±åƒæ··åˆå™ªå£°å»é™¤æ–¹æ³•ç ”ç©¶, 62401095, 2025.01-2027.12, <b>ä¸»æŒ</b></li>
<li><b>ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘ç‰¹åˆ«èµ„åŠ©</b>, åŸºäºå¤šæºä¿¡æ¯èåˆçš„é™æ­¢å«æ˜Ÿæ—©æœŸé‡ç«æ£€æµ‹æ–¹æ³•ç ”ç©¶, 2025T180065, 2025.07-2027.12, <b>ä¸»æŒ</b></li>
<li><b>ä¸­å›½åšå£«åç§‘å­¦åŸºé‡‘é¢ä¸Šé¡¹ç›®</b>, è”åˆæ—¶-ç©º-è°±ä¸€ä½“åŒ–ä¿¡æ¯çš„é¥æ„Ÿå½±åƒå»äº‘æ–¹æ³•ç ”ç©¶, 2023M740460, 2023.11-2025.12, <b>ä¸»æŒ</b></li>
<li><b>è¾½å®çœåšå£«ç§‘ç ”å¯åŠ¨é¡¹ç›®</b>, é¢å‘å›½äº§é«˜å…‰è°±é¥æ„Ÿå«æ˜Ÿçš„å¤šç±»å‹æ··åˆå™ªå£°å»é™¤æ–¹æ³•ç ”ç©¶, BQ626018, 2026.01-2027.12, <b>ä¸»æŒ</b></li>
<li><b>å¤§è¿å¸‚ç§‘æŠ€äººæ‰åˆ›æ–°æ”¯æŒé¡¹ç›® (å¤§è¿å¸‚é’å¹´ç§‘æŠ€ä¹‹æ˜Ÿ)</b>, é¥æ„Ÿä¿¡æ¯æ™ºèƒ½å¤„ç†ä¸åº”ç”¨, 2024RQ028, 2025.01-2026.12, <b>ä¸»æŒ</b></li>
<li><b>é¥æ„Ÿç§‘å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤å¼€æ”¾åŸºé‡‘</b>, é«˜å…‰è°±é¥æ„Ÿå½±åƒè‡ªç›‘ç£å»å™ªæ–¹æ³•ç ”ç©¶, OFSLRSS202301, 2023.08-2025.12, <b>ä¸»æŒ</b></li>
<li><b>ä¸­å¤®é«˜æ ¡åŸºæœ¬ç§‘ç ”ä¸šåŠ¡è´¹</b>, é¢å‘å›½äº§é¥æ„Ÿå«æ˜Ÿçš„æ—¶ç©ºè°±ä¿¡æ¯èåˆæ–¹æ³•ç ”ç©¶, 3132025267, 2025.01-2025.12, <b>ä¸»æŒ</b></li>
<li><b>ä¸­å¤®é«˜æ ¡åŸºæœ¬ç§‘ç ”ä¸šåŠ¡è´¹</b>, é¢å‘å…¨å¤©å€™ä»»åŠ¡çš„å¤šæºé¥æ„Ÿä¿¡æ¯èåˆæ–¹æ³•ç ”ç©¶, 3132024262, 2024.01-2024.12, <b>ä¸»æŒ</b></li>
<li><b>ä¸­å¤®é«˜æ ¡åŸºæœ¬ç§‘ç ”ä¸šåŠ¡è´¹</b>, é¥æ„Ÿé«˜æ—¶-ç©º-è°±ä¸€ä½“åŒ–ä¿¡æ¯èåˆæ–¹æ³•ç ”ç©¶, 3132023262, 2023.01-2023.12, <b>ä¸»æŒ</b></li>
<li><b>å¤§è¿æµ·äº‹å¤§å­¦äººæ‰ç§‘ç ”å¯åŠ¨è´¹</b>, å…´æµ·å‰¯æ•™æˆé«˜å±‚æ¬¡å¼•è¿›äººæ‰é¡¹ç›®, 02500363, 2022.07-2025.12, <b>ä¸»æŒ</b></li>
</ul>
</font>
<br />




<A NAME="Teaching"><h2>Teaching</h2></A>
<p><b>æœ¬ç§‘ç”Ÿè¯¾ç¨‹</b>: </p>
<font size="3"> 
<ul>
<li><b>ã€Šè®¡ç®—æœºè§†è§‰ã€‹</b>, ä¸“ä¸šé™é€‰, 40å­¦æ—¶</li>
<li><b>ã€Šç¦»æ•£æ•°å­¦ã€‹</b>, ä¸“ä¸šå¿…ä¿®, 64å­¦æ—¶</li>
</ul>
</font>
<br />
<br />
<br />

<p><b>ç ”ç©¶ç”Ÿè¯¾ç¨‹</b>: </p>
<font size="3"> 
<ul>
<li><b>ã€Šé¥æ„Ÿä¿¡æ¯å¤„ç†ã€‹</b>, ä¸“ä¸šé€‰ä¿®, 6å­¦æ—¶</li>
</ul>
</font>
<br />



<A NAME="Students"><h2>Students</h2></A>

<p><b>2022çº§ç¡•å£«ç”Ÿ</b>: </p>
<font size="3"> 
<ul>
<li><b>è‘£ç¾½å¸…</b>: <i>IEEE TGRS</i> 1ç¯‡ã€<i>IEEE GRSL</i> 1ç¯‡ã€åœ¨æŠ•è®ºæ–‡1ç¯‡ï¼Œ<b><font color="#FF0000">ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ã€è¾½å®çœä¼˜ç§€æ¯•ä¸šç”Ÿã€ä¼˜ç§€ç ”ç©¶ç”Ÿ</font></b>; æ¯•ä¸šå»å‘ï¼š<b>æ¯”äºšè¿ª</b></li>
<li><b>éƒ‘äºšæ˜</b>: <i>IEEE TNNLS</i> 1ç¯‡ã€<i>EAAI</i> 1ç¯‡ã€åœ¨æŠ•è®ºæ–‡1ç¯‡ï¼Œ<b><font color="#FF0000">æ‹›å•†è½®èˆ¹å¥–å­¦é‡‘ã€å¤§è¿å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿã€ä¼˜ç§€ç ”ç©¶ç”Ÿ</font></b>; æ¯•ä¸šå»å‘ï¼š<b>æºç¨‹</b></li>
<li><b>æœ±&nbsp;&nbsp;&nbsp;&nbsp;å¥</b>: <i>JAG</i> 1ç¯‡ã€<i>Neurocomputing</i> 1ç¯‡ã€åœ¨æŠ•è®ºæ–‡1ç¯‡ï¼Œ<b><font color="#FF0000">å¤§è¿æµ·äº‹å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿã€ä¼˜ç§€ç ”ç©¶ç”Ÿ</font></b>; æ¯•ä¸šå»å‘ï¼š<b>å¿«æ‰‹</b></li>
</ul>
</font>
<br />

<p><b>2023çº§ç¡•å£«ç”Ÿ</b>: </p>
<font size="3"> 
<ul>
<li><b>ç‹&nbsp;&nbsp;&nbsp;&nbsp;çª</b>: <i>ESWA</i> 1ç¯‡</li>
<li><b>åˆ˜å­æ«</b>: åœ¨æŠ•è®ºæ–‡1ç¯‡</li>
<li><b>å¼ æ˜¾é¹</b>: å¤§ä¿®è®ºæ–‡1ç¯‡</li>
</ul>
</font>
<br />

<p><b>2024çº§ç¡•å£«ç”Ÿ</b>: </p>
<font size="3"> 
<ul>
<li><b>é«˜æ–‡é™</b>: åœ¨æŠ•è®ºæ–‡2ç¯‡</li>
<li><b>è°¢å®æ°</b>: åœ¨æŠ•è®ºæ–‡1ç¯‡</li>
<li><b>åˆ˜&nbsp;&nbsp;&nbsp;&nbsp;åš</b>: åœ¨æŠ•è®ºæ–‡1ç¯‡</li>
<li><b>å¼ å®å¢¨</b>: åœ¨æŠ•è®ºæ–‡1ç¯‡</li>
</ul>
</font>
<br />

<p><b>2025çº§ç¡•å£«ç”Ÿ</b>: </p>
<font size="3"> 
<ul>
<li><b>ç‹å­ç¡•</b>: </li>
<li><b>å­™å¨æŒ¯</b>: </li>
<li><b>æ¨åŒå¾·</b>: </li>
</ul>
</font>
<br />
 
<p><b>2026çº§ç¡•å£«ç”Ÿ</b>: </p>
<font size="3"> 
<ul>
<li></b><b><font color="#FF0000">æŠ¥åæ‹›ç”Ÿä¸­...</font></b></li>
</ul>
</font>
<br />
 

 
<A NAME="Services"><h2>Services</h2></A>
 
<p><b>Editorial Board</b>: </p>
<font size="3"> 
<ul>
<li>Remote Sensing, <b>Leading Guest Editor</b> (Special Issue: <a href= "https://www.mdpi.com/journal/remotesensing/special_issues/568Q185F7Q" target="_blank">Trends and Prospects in Hyperspectral Remote Sensing Images Processing and Analysis</a>), <font color="#FF0000"><b>Submission Deadline: 2025.09.15</b></font></li>
</ul>
</font>
<br />
<br />
<br />
 
<p><b>Conference Organization</b>: </p>
<font size="3"> 
<ul>
<li>2023å¹´å…¨å›½çƒ­çº¢å¤–é¥æ„Ÿå¤§ä¼š, <b>ç»„ç»‡å§”å‘˜ä¼šå§”å‘˜</b></li>
<li>IGARSS 2021, <b>Session Chair</b> (Session: <a href= "https://igarss2021.com/view_session.php?SessionID=1105" target="_blank">Image Restoration</a>)</li>
</ul>
</font>
<br />
<br />
<br />
 
<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>IEEE, <b>Member</b></li>
<li>ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼š, <b>ä¼šå‘˜</b></li>
<li>ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼šé¥æ„Ÿå›¾åƒä¸“ä¸šå§”å‘˜ä¼š, <b>å§”å‘˜</b></li>

</ul>
</font>
<br />
<br />
<br />
 
<p><b>Journal Reviewer</b>: </p>
<font size="3"> 
<ul>
<li><b>IEEE</b>: TPAMI/TIP/TNNLS/TCSVT/TGRS/TCYB/TSP/TII/TETCI/GRSM/JSTARS/GRSL/SPL</li>
<li><b>Elsevier</b>: RSE/ISPRS/INFFUS/ESWA/EAAI/AFM/SRS/NN/Neurocomputing</li>
<li><b>Springer</b>: IJCV/EURASIP/CC/TVC/EI</li>
<li><b>Taylor&Francis</b>: GSIS/IJRS</li>
<li><b>MDPI</b>: RS/Sensors</li>
<li><b>...</b></li>
</ul>
</font>
<br />

 
 <A NAME="Resources"><h2>Resources</h2></A>

<p><b>Codes</b>: </p>
<font size="3"> 
<ul>
<li>FTAN (<a href= "https://github.com/chirsycy/FTAN" target="_blank">Code</a>)</li>
<li>TDSAT (<a href= "https://github.com/Featherrain/TDSAT" target="_blank">Code</a>)</li>
<li>PSTCR (<a href= "https://github.com/qzhang95/PSTCR" target="_blank">Code</a>)</li>
<li>BSVSR (<a href= "https://github.com/XY-boy/Blind-Satellite-VSR" target="_blank">Code</a>)</li>
<li>DICMA (<a href= "https://github.com/Chirsycy/DICMA" target="_blank">Code</a>)</li>
<li>SGD-SM (<a href= "https://github.com/qzhang95/SGD-SM" target="_blank">Code</a>)</li>
<li>STS-CNN (<a href= "https://github.com/qzhang95/STS-CNN" target="_blank">Code</a>)</li>
<li>HSID-CNN (<a href= "https://github.com/qzhang95/HSID-CNN" target="_blank">Code</a>)</li>
<li>MSTT-STVSR (<a href= "https://github.com/XY-boy/MSTT-STVSR" target="_blank">Code</a>)</li>
</ul>
</font>
<br />
<br />
<br />
 
<p><b>Datasets</b>: </p>
<font size="3"> 
<ul>
<li>SGD-SM V2.0 (<a href= "https://doi.org/10.5281/zenodo.6041561" target="_blank">Dataset</a>)</li>
<li>SGD-SM V1.0 (<a href= "https://doi.org/10.5281/zenodo.4417458" target="_blank">Dataset</a>)</li>
<li>SGD-SST V2.0 (Coming soon!)</li>
<li>SGD-SST V1.0 (<a href= "https://zenodo.org/records/14064951" target="_blank">Dataset</a>)</li>
<li>HSI Denoising Dataset V2.0 (<a href= "https://drive.google.com/file/d/1mZ_dsfrZ_lQiDwe4__Lmaf5GIpXesPf5/view?usp=sharing" target="_blank">Dataset</a>)</li>
<li>HSI Denoising Dataset V1.0 (<a href= "https://wwa.lanzoui.com/iNjl9dna1vi" target="_blank">Dataset</a>)</li>
<li>Multi-Temporal Sentinel-2 Cloud Detection and Removal Dataset V1.0 (<a href= "https://drive.google.com/file/d/1LlvUKtUWAKoF6R0igbREwvP2Wfja9UBv/view?usp=sharing" target="_blank">Dataset</a>)</li>
</ul>
</font>
<br /> 
 
 
 

<A NAME="Awards"><h2>Awards</h2></A>
<font size="4">
<ul><b>
<li>2025, <font style="font-family:Microsoft YaHei">æŒ‡å¯¼ç¡•å£«ç”Ÿè‘£ç¾½å¸…è·è¾½å®çœä¼˜ç§€æ¯•ä¸šç”Ÿï¼Œè¾½å®çœæ•™è‚²å…</font></li>
<li>2025, <font style="font-family:Microsoft YaHei">æŒ‡å¯¼ç¡•å£«ç”Ÿéƒ‘äºšæ˜è·å¤§è¿å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿï¼Œå¤§è¿å¸‚æ•™è‚²å±€</font></li>
<li>2025, <font style="font-family:Microsoft YaHei">æŒ‡å¯¼ç¡•å£«ç”Ÿæœ±å¥è·å¤§è¿æµ·äº‹å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿï¼Œå¤§è¿æµ·äº‹å¤§å­¦</font></li>
<li>2025, <font style="font-family:Microsoft YaHei">å¤§è¿å¸‚è‡ªç„¶ç§‘å­¦äºŒç­‰å¥–ï¼Œæ’å2ï¼Œå¤§è¿å¸‚äººæ°‘æ”¿åºœ</font></li>
<li>2024, <font style="font-family:Microsoft YaHei">å¤§è¿å¸‚é’å¹´ç§‘æŠ€ä¹‹æ˜Ÿï¼Œå¤§è¿å¸‚ç§‘æŠ€å±€</font></li>
<li>2024, <font style="font-family:Microsoft YaHei">æŒ‡å¯¼ç¡•å£«ç”Ÿè‘£ç¾½å¸…è·ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ï¼Œä¸­åäººæ°‘å…±å’Œå›½æ•™è‚²éƒ¨</font></li>
<li>2023, <font style="font-family:Microsoft YaHei">æŒ‡å¯¼ç¡•å£«ç”Ÿéƒ‘äºšæ˜è·æ‹›å•†è½®èˆ¹å¥–å­¦é‡‘ï¼Œå¤§è¿æµ·äº‹å¤§å­¦</font></li>
<li>2023, <font style="font-family:Microsoft YaHei">å¤§è¿å¸‚é«˜å±‚æ¬¡å¼•è¿›äººæ‰é’å¹´æ‰ä¿Šï¼Œå¤§è¿å¸‚å§”äººæ‰åŠ</font></li>
<li>2022, <font style="font-family:Microsoft YaHei">å¤§è¿æµ·äº‹å¤§å­¦â€œå…´æµ·â€é«˜å±‚æ¬¡äººæ‰ï¼Œå¤§è¿æµ·äº‹å¤§å­¦</font></li>
<li>2022, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦åå¤§æ°å‡ºé’å¹´ (å­¦ç”Ÿ)ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2022, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦ä¼˜ç§€æ¯•ä¸šç ”ç©¶ç”Ÿï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2021, <font style="font-family:Microsoft YaHei"><b><font color="#FF0000">æå°æ–‡é¥æ„Ÿç§‘å­¦é’å¹´å¥–</font>ï¼Œæå°æ–‡åŸºé‡‘ç†äº‹ä¼š</b></font></li>
<li>2021, <font style="font-family:Microsoft YaHei">åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ï¼Œä¸­åäººæ°‘å…±å’Œå›½æ•™è‚²éƒ¨</font></li>
<li>2021, <font style="font-family:Microsoft YaHei">å…¨å›½æˆåƒå…‰è°±å¯¹åœ°è§‚æµ‹ç ”è®¨ä¼šä¼˜ç§€æŠ¥å‘Šå¥–ï¼Œå¤§ä¼šå­¦æœ¯å§”å‘˜ä¼š</font></li>
<li>2021, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦å­¦ä¸šå¥–å­¦é‡‘ä¸€ç­‰å¥–ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2021, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦ä¼˜ç§€ç ”ç©¶ç”Ÿæ ‡å…µï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦â€œç ”ç©¶ç”Ÿå­¦æœ¯åˆ›æ–°å¥–â€ç‰¹ç­‰å¥– (<b><font color="#FF0000">æ ¡é•¿å¥–</font></b>)ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">ç‹ä¹‹å“åˆ›æ–°äººæ‰å¥–ç‰¹ç­‰å¥–ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">ä¸­å›½å¤§å­¦ç”Ÿè‡ªå¼ºä¹‹æ˜Ÿï¼Œå…±é’å›¢ä¸­å¤®</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">æ¹–åŒ—çœå¤§å­¦ç”Ÿè‡ªå¼ºä¹‹æ˜Ÿæ ‡å…µï¼Œæ¹–åŒ—çœå­¦è”</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦å­¦ä¸šå¥–å­¦é‡‘ä¸€ç­‰å¥–ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2020, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦ä¼˜ç§€ç ”ç©¶ç”Ÿï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2019, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦ç ”ç©¶ç”Ÿâ€œåå¤§åŠ±å¿—ä¹‹æ˜Ÿâ€ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2019, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦å…‰åå¥–å­¦é‡‘ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2018, <font style="font-family:Microsoft YaHei">ç¡•å£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ï¼Œä¸­åäººæ°‘å…±å’Œå›½æ•™è‚²éƒ¨</font></li>
<li>2018, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦å­¦ä¸šå¥–å­¦é‡‘ä¸€ç­‰å¥–ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2018, <font style="font-family:Microsoft YaHei">ç¬¬åå±Šâ€œä¹ç¾¤å­¦æœ¯ä¹‹æ˜Ÿâ€ï¼Œæ­¦æ±‰å¤§å­¦æµ‹ç»˜å­¦é™¢</font></li>
<li>2017, <font style="font-family:Microsoft YaHei">æ­¦æ±‰å¤§å­¦ä¼˜ç§€æœ¬ç§‘æ¯•ä¸šç”Ÿï¼Œæ­¦æ±‰å¤§å­¦</font></li>
<li>2015, <font style="font-family:Microsoft YaHei">å›½å®¶åŠ±å¿—å¥–å­¦é‡‘ï¼Œæ­¦æ±‰å¤§å­¦</font></li>
</ul></b>
</font>
 
<br />
<br />

<div id="footer">
<p style="text-align:center;">Copyright @ 2020-2025 Qiang Zhang. All rights reserved.</p>
</div> 

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


</body>
</html>
