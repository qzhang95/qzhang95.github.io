<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link href="main.css" rel="stylesheet" media="all">
<meta name="description" content="Generating Seamless Global Daily AMSR2 Soil Moisture Long-term Productions (2013-2019)" />
<meta name="keywords" content="AMSR2">
<!--
<meta name="msvalidate.01" content="BF499F7308096080ECD26FCFFCEA47FD" />
<meta name="google-site-verification" content="21kKbFxBFeevz2yaI7Nn40dIYxOaLukGDpHBZbzLyt0" />
!-->
<title>Generating Seamless Global Daily AMSR2 Soil Moisture Long-term Productions (2013-2019)</title>
</head>

<body>
</br></br>
<h2 class="auto-style1">Generating Seamless Global Daily AMSR2 Soil Moisture Long-term Productions (2013-2019)</h2>
<p class="auto-style7"  align="center"><a href="https://qzhang95.github.io">Qiang Zhang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp; 
<a href="https://www.researchgate.net/profile/Yuan_Wang209">Yuan Wang</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp; 
<a href="http://qqyuan.users.sgg.whu.edu.cn/">Qiangqiang Yuan</a><sup>2</sup>&nbsp;&nbsp;&nbsp;&nbsp; 
<a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Liangpei Zhang</a><sup>1</sup></p>
<p class="auto-style7"  align="center"></a><sup>1</sup><i>State Key Laboratory of Information Engineering, Survey Mapping and Remote Sensing, Wuhan Univeristy</i></br></p>
<p class="auto-style7"  align="center"></a><sup>2</sup><i>School of Geodesy and Geomatics, Wuhan Univeristy</i></br></p>
<!--<p class="auto-style7"  align="center">&nbsp;&nbsp;&nbsp; </p>-->

<p align="center">
<table style="width:840px" align="center">
<tr>
	<td><img width=600px alt="" src="figures/Original_AMSR2.gif"></td>	
</tr>
<tr>
	<td><p class="auto-style11-c">Fig. 1. Original AMSR2 Time-series Productions</p></td>
</tr>
</table>

<p class="style2"><strong><span class="auto-style6">Abstract</span></strong></p>
<p class="auto-style5">High quality and long-term soil moisture productions are significant for hydrologic monitoring and agricultural management. However, the acquired daily soil moisture productions are incomplete in global land (about 30%~80%), due to the satellite orbit coverage and the limitations of soil moisture retrieving algorithms. To solve this inevitable problem, we develop a novel 3-D spatio-temporal partial convolutional neural network for Advanced Microwave Scanning Radiometer 2 (AMSR2) soil moisture productions gap-filling. Through the proposed method, we generate the seamless global daily AMSR2 soil moisture long-term productions from 2013 to 2019. To further validate the effectiveness of these productions, three verification ways are employed as follow: 1) in-situ validation, 2) Time-series validation, and 3) simulated missing regions validation. Results show that the reconstructing soil moisture productions have good agreement with the selected 999 ISMN stations (correlation coefficient: 0.99-0.99, overall bias: -0.4-1.8 m3/m3). The temporal continuity of the daily long-term productions is ensured with the original time-series distribution (correlation coefficient: 0.99-0.99, overall bias: -0.4-1.8 m3/m3,). Besides, the spatial uniformity of the reconstructing regions is also accord with the context information. (correlation coefficient: 0.99-0.99, overall bias: -0.4-1.8 m3/m3).</p>
<p class="auto-style5">&nbsp;</p>


<p id="downloads", class="auto-style4"><strong>Downloads</strong></p>

<table cellSpacing=4 cellPadding=2 border=0 style="width: 90%">
<tr COLSPAN="2">
<td align="center" valign="center">
<img style="padding:0; clear:both; " src="Figures/paper_thumbnail.png" align="middle" alt="Snapshot for paper" class="pdf" width="170" /></td>
<td align="left" class="auto-style5">
"Handling Motion Blur in Multi-Frame Super-Resolution&quot;<br>
Ziyang Ma, Renjie Liao, Xin Tao, Li Xu, Jiaya Jia, Enhua Wu <br>
IEEE Conference on Computer Vision and Pattern Recognition (<b>xxxx</b>), 2020<br><br>
<img alt="" height="32" src="Figures/pdf_icon.gif" width="31">&nbsp;&nbsp;
[<a href="./papers/mfsr_final.pdf">Paper</a>] <!--[<a href="./bibtex.html">BibTeX</a>]--><br>
<img alt="" height="32" src="Figures/pdf_icon.gif" width="31">&nbsp;&nbsp;
[<a href="./papers/mfsr_supp.pdf">Supplementary Material</a>] <!--[<a href="./bibtex.html">BibTeX</a>]--><br>
<img alt="" height="36" src="Figures/software.gif" width="36">&nbsp; [<a href="data/mfsr_pcode_v0.2.zip">Code v0.2 (MATLAB p-code, 2016-01-01)</a>] 
<br>
<img alt="" height="35" src="Figures/data_icon.png" width="35"> &nbsp;[<a href="./data/mfsr_data.zip">Data and Results (2015-07-29)</a>] <br>
<!--<img alt="" height="35" src="figures/zip_icons.jpg" width="35"> &nbsp;[<a href="data/BlurDatasetResultShi.zip">Results</a>] <br>
<!--<img alt="" height="36" src="figures/poster_small.jpg" width="35">&nbsp; [<a href="Poster.pdf">Poster</a>] <br>-->
</td>
</tr>
</table>
<br>

<p class="auto-style4" id=experiment><strong>Experiments</strong></p>
<table border="0" align="center">
<tr>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_1.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_2.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_3.png"></td>
</tr>
<tr>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_4.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_5.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=270px src="Figures/results/celiu_seq_6.png"></td>
</tr>
<tr>
<td class="auto-style11-c">(a) Bicubic ×4</td>
<td class="auto-style11-c">(b) Results with high-res flow</td>
<td class="auto-style11-c">(c) Results with interpolated low-res flow</td>
</tr>
<tr>
</table>
<p class="auto-style11-c">Fig. 2 Using TV-L1 based optical flow on the low-res grid yields reasonable results. (a) One input frame with bicubic ×4. (b) Results of using high-res flow [4]. (c) Results of using the interpolated low-res TV-L1 flow [5].</p>

<table border="0" align="center">
<tr>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_1.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_2.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_3.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_4.png"></td>
</tr>
<tr>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_5.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_6.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_7.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=210px src="Figures/results/comp1_8.png"></td>
</tr>
<tr>
<td class="auto-style11-c">(a) Selected input frames</td>
<td class="auto-style11-c">(b) Deblur + SR</td>
<td class="auto-style11-c">(c) Results w/o sharpness mask</td>
<td class="auto-style11-c">(d) Our final results</td>
</tr>
<tr>
</table>
<p class="auto-style11-c">Fig. 3 More results and comparison (×3). (a) Four input frames from each sequence. (b) Results of multi-image deblurring [6] followed by super-resolution [4]. (c) Results without sharpness mask (β = ∞). (d) Our results with the sharpness masks (β = 1.4).</p>

<table border="0" align="center">
<tr>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=300px src="Figures/results/exp_noise1.png"></td>
<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=300px src="Figures/results/exp_noise2.png"></td>
</tr>
<tr>
<td class="auto-style11-c">(a) Selected input frames</td>
<td class="auto-style11-c">(b) Our results</td>
</tr>
<tr>
</table>
<p class="auto-style11-c">Fig. 4 Our method is robust to noise. (a) A few relative sharp input frames. (b) Our results (×3).</p>


<p class="auto-style4" id=results><strong>Results</strong></p>
<p class="auto-style5"><font color="red"><b>All results of our method are available <a href="">here (coming soon)</a>.</b></font></p>

<table border="0" align="center">
<tr>
<td colspan=2 style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=600 src="Figures/results/res1_1.png"></td>
</tr>
<tr>
	<td colspan=2 class="auto-style11-c">(a) Selected input frames</td>
</tr>
<tr>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=300px src="Figures/results/res1_2.png"></td>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img width=300px src="Figures/results/res1_3.png"></td>
</tr>
<tr>
	<td class="auto-style11-c">(b) Result of [7]</td>
	<td class="auto-style11-c">(c) Our result</td>
</tr>
<tr>
</table>
<p class="auto-style11-c">Fig. 5 More results and comparison (×3). (a) Four input frames from a sequence. (b) Multi-shot image result [7]. (c) Our result.</p>

<table border="0" align="center">
<tr>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=400 src="Figures/results/real1.png"></td>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=400 src="Figures/results/real2.png"></td>
</tr>
</table>
<table border="0" align="center">
<tr>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=288px src="Figures/results/real3.png"></td>
	<td style="width: 4rem;height: 2rem;border: 1px solid #ccc;text-align: center"><img height=288px src="Figures/results/real4.png"></td>
</tr>
<tr>
	<td class="auto-style11-c">(a) Selected input frames (with zoom-in)</td>
	<td class="auto-style11-c">(b) Our results</td>
</tr>
<tr>
</table>
<p class="auto-style11-c">Fig. 6 More natural video results. (a) Sample input frames. (b) Our results estimated using 31 low-res frames each.</p>



<p class="auto-style4" id=results><strong>Reference</strong></p>
<p id="ref_1" class="auto-style5">
	[1] L. Xu, S. Zheng, and J. Jia. Unnatural l0 sparse representation for natural image deblurring. In CVPR, pages 1107–1114, 2013.</p>
<p id="ref_2" class="auto-style5">
	[2] S. Cho, J. Wang, and S. Lee. Video deblurring for hand-held cameras using patch-based synthesis. ACM Transactions on Graphics (TOG), 31(4):64, 2012.</p>
<p id="ref_2" class="auto-style5">
	[3] Q. Shan, Z. Li, J. Jia, and C.-K. Tang. Fast image/video upsampling. ACM Transactions on Graphics (TOG), 27(5):153, 2008.</p>
<p id="ref_2" class="auto-style5">
	[4] C. Liu and D. Sun. A bayesian approach to adaptive video super resolution. In CVPR, pages 209–216, 2011.</p>	
<p id="ref_2" class="auto-style5">
	[5] T. Brox, A. Bruhn, N. Papenberg, and J. Weickert. High accuracy optical flow estimation based on a theory for warping. In ECCV, pages 25–36, 2004.</p>
<p id="ref_2" class="auto-style5">
	[6] X. Zhu, F. ˇSroubek, and P. Milanfar. Deconvolving psfs for a better motion deblurring using multiple images. In ECCV, pages 636–647, 2012. </p>	
<p id="ref_2" class="auto-style5">

<p class="auto-style5">&nbsp;</p>


<p>&nbsp;</p>
<p>&nbsp;</p>


</body>

</html>
